{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d23dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Student Dropout Prediction – Prototype\n",
    "# Dataset: UCI \"Predict Students' Dropout and Academic Success\" (ID: 697)\n",
    "\n",
    "# 1. Imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "\n",
    "# 2. Load dataset from UCI\n",
    "\n",
    "dataset =  pd.read_csv(\"data.csv\") # Predict Students' Dropout and Academic Success\n",
    "\n",
    "X = dataset.data.features\n",
    "y = dataset.data.targets\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Targets shape:\", y.shape)\n",
    "print(\"Target columns:\", y.columns)\n",
    "\n",
    "# For this dataset, the target column is often named something like 'Target'\n",
    "# Show first few rows to confirm:\n",
    "display(y.head())\n",
    "\n",
    "\n",
    "# 3. Prepare features (X) and target (y)\n",
    "\n",
    "# If there is only one target column, convert to 1D array\n",
    "if y.shape[1] == 1:\n",
    "    y = y.iloc[:, 0]\n",
    "else:\n",
    "    # If there are multiple target columns, pick the main status column\n",
    "    # Adjust this line to the actual column name if needed\n",
    "    y = y['Target']  # change if your column is named differently\n",
    "\n",
    "print(\"Unique target values:\", y.unique())\n",
    "\n",
    "\n",
    "# 4. Train-test split (80/20 recommended by dataset authors)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape, \"Test size:\", X_test.shape)\n",
    "\n",
    "\n",
    "# 5. Identify numeric and categorical columns\n",
    "\n",
    "numeric_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = X_train.select_dtypes(exclude=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(\"Numeric columns:\", len(numeric_cols))\n",
    "print(\"Categorical columns:\", len(categorical_cols))\n",
    "\n",
    "\n",
    "# 6. Preprocessing pipeline\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# 7. Baseline model – Multinomial Logistic Regression\n",
    "\n",
    "log_reg = LogisticRegression(\n",
    "    multi_class=\"multinomial\",\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\"  # handle class imbalance\n",
    ")\n",
    "\n",
    "log_reg_clf = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", log_reg)\n",
    "])\n",
    "\n",
    "log_reg_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_log = log_reg_clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(\"=== Logistic Regression – Test Performance ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_log))\n",
    "print(classification_report(y_test, y_pred_log))\n",
    "\n",
    "cm_log = confusion_matrix(y_test, y_pred_log, labels=y.unique())\n",
    "disp_log = ConfusionMatrixDisplay(confusion_matrix=cm_log, display_labels=y.unique())\n",
    "disp_log.plot(xticks_rotation=45)\n",
    "plt.title(\"Logistic Regression – Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 8. Advanced model – Random Forest\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced_subsample\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_clf = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", rf)\n",
    "])\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "print(\"=== Random Forest – Test Performance ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf, labels=y.unique())\n",
    "disp_rf = ConfusionMatrixDisplay(confusion_matrix=cm_rf, display_labels=y.unique())\n",
    "disp_rf.plot(xticks_rotation=45)\n",
    "plt.title(\"Random Forest – Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 9. Cross-validation on training set (optional, for robustness)\n",
    "\n",
    "cv_scores = cross_val_score(\n",
    "    rf_clf,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    scoring=\"f1_weighted\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Random Forest 5-fold CV F1 (weighted):\", cv_scores)\n",
    "print(\"Mean F1:\", cv_scores.mean(), \"Std:\", cv_scores.std())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#save the models\n",
    "joblib.dump(log_reg_clf, \"student_dropout_logreg_model.pkl\")\n",
    "joblib.dump(rf_clf, \"student_dropout_rf_model.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Load the trained pipeline\n",
    "# ---------------------------\n",
    "MODEL_PATH1= \"student_dropout_logreg_model.pkl\"\n",
    "pipeline1 = joblib.load(MODEL_PATH1)\n",
    "MODEL_PATH2= \"student_dropout_rf_model.pkl\"\n",
    "pipeline2 = joblib.load(MODEL_PATH2)\n",
    "\n",
    "# ---------------------------\n",
    "# Example new student input\n",
    "# ---------------------------\n",
    "new_student = {\n",
    "    'Marital Status': 1,\n",
    "    'Application mode': 1,\n",
    "    'Application order': 2,\n",
    "    'Course': 1,\n",
    "    'Daytime/evening attendance': 1,\n",
    "    'Previous qualification': 1,\n",
    "    'Previous qualification (grade)': 120.0,\n",
    "    'Nacionality': 1,\n",
    "    \"Mother's qualification\": 2,\n",
    "    \"Father's qualification\": 2,\n",
    "    \"Mother's occupation\": 4,\n",
    "    \"Father's occupation\": 4,\n",
    "    'Admission grade': 140.0,\n",
    "    'Displaced': 0,\n",
    "    'Educational special needs': 0,\n",
    "    'Debtor': 0,\n",
    "    'Tuition fees up to date': 1,\n",
    "    'Gender': 1,\n",
    "    'Scholarship holder': 0,\n",
    "    'Age at enrollment': 19,\n",
    "    'International': 0,\n",
    "    'Curricular units 1st sem (credited)': 0,\n",
    "    'Curricular units 1st sem (enrolled)': 6,\n",
    "    'Curricular units 1st sem (evaluations)': 6,\n",
    "    'Curricular units 1st sem (approved)': 5,\n",
    "    'Curricular units 1st sem (grade)': 13.2,\n",
    "    'Curricular units 1st sem (without evaluations)': 0,\n",
    "    'Curricular units 2nd sem (credited)': 0,\n",
    "    'Curricular units 2nd sem (enrolled)': 6,\n",
    "    'Curricular units 2nd sem (evaluations)': 6,\n",
    "    'Curricular units 2nd sem (approved)': 6,\n",
    "    'Curricular units 2nd sem (grade)': 14.1,\n",
    "    'Curricular units 2nd sem (without evaluations)': 0,\n",
    "    'Unemployment rate': 6.5,\n",
    "    'Inflation rate': 1.2,\n",
    "    'GDP': 2.1\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# Convert to DataFrame\n",
    "# ---------------------------\n",
    "df_new = pd.DataFrame([new_student])\n",
    "\n",
    "# ---------------------------\n",
    "# Run Prediction\n",
    "# ---------------------------\n",
    "prediction = pipeline1.predict(df_new)[0]\n",
    "prediction2 = pipeline2.predict(df_new)[0]\n",
    "\n",
    "print(\"======================================\")\n",
    "print(\" Predicted Student Outcome:\", prediction)\n",
    "print(\"======================================\")\n",
    "print(\" Predicted Student Outcome (RF):\", prediction2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad3ae43",
   "metadata": {},
   "source": [
    "Solving the classification problem using deep learning tecnique TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b522ad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ============================================================\n",
    "# 0. IMPORTS & SETUP\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers, utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. LOAD DATA\n",
    "# ============================================================\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "print(\"\\nDataset loaded. Shape:\", df.shape)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=[\"Target\"])\n",
    "y = df[\"Target\"]\n",
    "\n",
    "# Identify categorical and numeric columns\n",
    "numeric_cols = [col for col in X.columns if X[col].dtype != \"object\"]\n",
    "categorical_cols = [col for col in X.columns if X[col].dtype == \"object\"]\n",
    "\n",
    "print(\"\\nNumeric columns:\", len(numeric_cols))\n",
    "print(\"Categorical columns:\", len(categorical_cols))\n",
    "\n",
    "# ============================================================\n",
    "# 2. TRAIN/TEST SPLIT\n",
    "# ============================================================\n",
    "\n",
    "X_train, X_test, y_train_raw, y_test_raw = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\nTrain shape:\", X_train.shape)\n",
    "print(\"Test shape :\", X_test.shape)\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "# ============================================================\n",
    "# 3. PREPROCESSING WITH COLUMNTRANSFORMER\n",
    "# ============================================================\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit/transform\n",
    "X_train_tf = preprocess.fit_transform(X_train)\n",
    "X_test_tf  = preprocess.transform(X_test)\n",
    "\n",
    "print(\"\\nTransformed train shape:\", X_train_tf.shape)\n",
    "print(\"Transformed test shape :\", X_test_tf.shape)\n",
    "\n",
    "# ============================================================\n",
    "# 4. LABEL ENCODING (for TensorFlow)\n",
    "# ============================================================\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_enc = label_encoder.fit_transform(y_train_raw)\n",
    "y_test_enc  = label_encoder.transform(y_test_raw)\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train_cat = utils.to_categorical(y_train_enc)\n",
    "y_test_cat  = utils.to_categorical(y_test_enc)\n",
    "\n",
    "num_classes = y_train_cat.shape[1]\n",
    "num_features = X_train_tf.shape[1]\n",
    "\n",
    "print(\"\\nClasses detected:\", label_encoder.classes_)\n",
    "print(\"Number of features:\", num_features)\n",
    "print(\"Number of classes:\", num_classes)\n",
    "\n",
    "# Convert float32 (required for TensorFlow)\n",
    "X_train_tf = X_train_tf.astype(\"float32\")\n",
    "X_test_tf = X_test_tf.astype(\"float32\")\n",
    "\n",
    "print(\"\\nData ready...\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. BUILD TENSORFLOW MODEL (same structure as your wine example)\n",
    "# ============================================================\n",
    "\n",
    "hl = 10  # hidden units\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(hl, input_dim=num_features, activation='relu'))\n",
    "model.add(Dense(hl, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "print(\"\\nModel Summary:\")\n",
    "print(model.summary())\n",
    "\n",
    "# ============================================================\n",
    "# 6. COMPILE MODEL\n",
    "# ============================================================\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 7. TRAINING\n",
    "# ============================================================\n",
    "\n",
    "num_epochs = 50\n",
    "history = model.fit(\n",
    "    X_train_tf, y_train_cat,\n",
    "    epochs=num_epochs,\n",
    "    batch_size=10,\n",
    "    validation_data=(X_test_tf, y_test_cat)\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 8. PLOT TRAINING LOSS & VALIDATION LOSS\n",
    "# ============================================================\n",
    "\n",
    "epoch_nums = range(1, num_epochs + 1)\n",
    "training_loss = history.history[\"loss\"]\n",
    "validation_loss = history.history[\"val_loss\"]\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(epoch_nums, training_loss)\n",
    "plt.plot(epoch_nums, validation_loss)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.legend([\"Training\", \"Validation\"])\n",
    "plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# 9. PRINT WEIGHTS & BIASES FOR EACH LAYER\n",
    "# ============================================================\n",
    "\n",
    "for layer in model.layers:\n",
    "    weights, biases = layer.get_weights()\n",
    "    print(\"\\n----------------------------------------\")\n",
    "    print(\"Layer:\", layer.name)\n",
    "    print(\"Weights:\\n\", weights)\n",
    "    print(\"Biases:\\n\", biases)\n",
    "\n",
    "# ============================================================\n",
    "# 10. CONFUSION MATRIX\n",
    "# ============================================================\n",
    "\n",
    "class_probs = model.predict(X_test_tf)\n",
    "predictions = np.argmax(class_probs, axis=1)\n",
    "true_labels = np.argmax(y_test_cat, axis=1)\n",
    "\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(num_classes)\n",
    "plt.xticks(tick_marks, label_encoder.classes_, rotation=45)\n",
    "plt.yticks(tick_marks, label_encoder.classes_)\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.ylabel(\"Actual Class\")\n",
    "plt.title(\"Confusion Matrix – TensorFlow Neural Network\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# 11. SAVE MODEL\n",
    "# ============================================================\n",
    "\n",
    "model_filename = \"student_dropout_tf_model.h5\"\n",
    "model.save(model_filename)\n",
    "print(\"\\nModel saved as:\", model_filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
